{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# libraries"
      ],
      "metadata": {
        "id": "Wouvb7TW45Rn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "TxRkOFRS43U4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's set device"
      ],
      "metadata": {
        "id": "h_PJXTx5EgOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLYJXaeK5C0A",
        "outputId": "e5ed12b1-d625-49f8-cb88-7af6592538d5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "gdFzp6tz43U6"
      },
      "outputs": [],
      "source": [
        "bs = 100\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "szSkpSld43U6"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim, g_output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        return torch.tanh(self.fc4(x))\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        return torch.sigmoid(self.fc4(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8D7REZYj43U6"
      },
      "outputs": [],
      "source": [
        "# build network\n",
        "z_dim = 100\n",
        "mnist_dim = train_dataset.train_data.size(1) * train_dataset.train_data.size(2)\n",
        "\n",
        "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\n",
        "D = Discriminator(mnist_dim).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCCuLO3x43U6",
        "outputId": "5a75089f-e5dd-4923-e5d3-dfd6d85bc680"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (fc1): Linear(in_features=100, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
              "  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSlgS6dh43U7",
        "outputId": "1ded7252-ed78-4cce-f469-1d480802c6fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5XtccGbg43U7"
      },
      "outputs": [],
      "source": [
        "# loss\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# optimizer\n",
        "lr = 0.0002\n",
        "G_optimizer = optim.Adam(G.parameters(), lr = lr)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr = lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "aNc96SQG43U7"
      },
      "outputs": [],
      "source": [
        "def D_train(x):\n",
        "    #=======================Train the discriminator=======================#\n",
        "    D.zero_grad()\n",
        "\n",
        "    # train discriminator on real\n",
        "    x_real, y_real = x.view(-1, mnist_dim), torch.ones(bs, 1)\n",
        "    x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\n",
        "\n",
        "    D_output = D(x_real)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "    D_real_score = D_output\n",
        "\n",
        "    # train discriminator on facke\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    x_fake, y_fake = G(z), Variable(torch.zeros(bs, 1).to(device))\n",
        "\n",
        "    D_output = D(x_fake)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "    D_fake_score = D_output\n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "\n",
        "    return  D_loss.data.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "QtQAUNEz43U8"
      },
      "outputs": [],
      "source": [
        "def G_train(x):\n",
        "    #=======================Train the generator=======================#\n",
        "    G.zero_grad()\n",
        "\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    y = Variable(torch.ones(bs, 1).to(device))\n",
        "\n",
        "    G_output = G(z)\n",
        "    D_output = D(G_output)\n",
        "    G_loss = criterion(D_output, y)\n",
        "\n",
        "    # gradient backprop & optimize ONLY G's parameters\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "\n",
        "    return G_loss.data.item()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 100\n",
        "\n",
        "test_z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "for epoch in range(1, n_epoch+1):\n",
        "    D_losses, G_losses = [], []\n",
        "    for batch_idx, (x, _) in enumerate(train_loader):\n",
        "        D_losses.append(D_train(x))\n",
        "        G_losses.append(G_train(x))\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        generated = G(test_z)\n",
        "        save_image(generated.view(generated.size(0), 1, 28, 28), f'./samples/sample{epoch}.png')\n",
        "\n",
        "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
        "        epoch, n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s-cQu5U9y-p",
        "outputId": "efd1a1ac-3e7b-4b4e-d5ff-00a94313b961"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/100]: loss_d: 0.835, loss_g: 3.442\n",
            "[2/100]: loss_d: 0.960, loss_g: 2.298\n",
            "[3/100]: loss_d: 1.061, loss_g: 1.858\n",
            "[4/100]: loss_d: 0.890, loss_g: 2.225\n",
            "[5/100]: loss_d: 0.713, loss_g: 2.059\n",
            "[6/100]: loss_d: 0.527, loss_g: 2.718\n",
            "[7/100]: loss_d: 0.589, loss_g: 2.399\n",
            "[8/100]: loss_d: 0.604, loss_g: 2.499\n",
            "[9/100]: loss_d: 0.655, loss_g: 2.369\n",
            "[10/100]: loss_d: 0.600, loss_g: 2.492\n",
            "[11/100]: loss_d: 0.624, loss_g: 2.427\n",
            "[12/100]: loss_d: 0.722, loss_g: 2.185\n",
            "[13/100]: loss_d: 0.668, loss_g: 2.330\n",
            "[14/100]: loss_d: 0.715, loss_g: 2.142\n",
            "[15/100]: loss_d: 0.761, loss_g: 2.031\n",
            "[16/100]: loss_d: 0.808, loss_g: 1.923\n",
            "[17/100]: loss_d: 0.803, loss_g: 1.886\n",
            "[18/100]: loss_d: 0.853, loss_g: 1.770\n",
            "[19/100]: loss_d: 0.871, loss_g: 1.683\n",
            "[20/100]: loss_d: 0.890, loss_g: 1.656\n",
            "[21/100]: loss_d: 0.877, loss_g: 1.693\n",
            "[22/100]: loss_d: 0.911, loss_g: 1.649\n",
            "[23/100]: loss_d: 0.920, loss_g: 1.626\n",
            "[24/100]: loss_d: 0.911, loss_g: 1.592\n",
            "[25/100]: loss_d: 0.961, loss_g: 1.501\n",
            "[26/100]: loss_d: 0.952, loss_g: 1.553\n",
            "[27/100]: loss_d: 0.963, loss_g: 1.492\n",
            "[28/100]: loss_d: 0.977, loss_g: 1.459\n",
            "[29/100]: loss_d: 1.001, loss_g: 1.416\n",
            "[30/100]: loss_d: 0.995, loss_g: 1.412\n",
            "[31/100]: loss_d: 1.027, loss_g: 1.349\n",
            "[32/100]: loss_d: 1.025, loss_g: 1.377\n",
            "[33/100]: loss_d: 1.021, loss_g: 1.381\n",
            "[34/100]: loss_d: 1.026, loss_g: 1.360\n",
            "[35/100]: loss_d: 1.055, loss_g: 1.300\n",
            "[36/100]: loss_d: 1.052, loss_g: 1.295\n",
            "[37/100]: loss_d: 1.081, loss_g: 1.256\n",
            "[38/100]: loss_d: 1.100, loss_g: 1.239\n",
            "[39/100]: loss_d: 1.082, loss_g: 1.245\n",
            "[40/100]: loss_d: 1.089, loss_g: 1.212\n",
            "[41/100]: loss_d: 1.115, loss_g: 1.189\n",
            "[42/100]: loss_d: 1.114, loss_g: 1.172\n",
            "[43/100]: loss_d: 1.125, loss_g: 1.154\n",
            "[44/100]: loss_d: 1.122, loss_g: 1.178\n",
            "[45/100]: loss_d: 1.124, loss_g: 1.173\n",
            "[46/100]: loss_d: 1.117, loss_g: 1.178\n",
            "[47/100]: loss_d: 1.151, loss_g: 1.113\n",
            "[48/100]: loss_d: 1.148, loss_g: 1.123\n",
            "[49/100]: loss_d: 1.137, loss_g: 1.140\n",
            "[50/100]: loss_d: 1.150, loss_g: 1.115\n",
            "[51/100]: loss_d: 1.160, loss_g: 1.104\n",
            "[52/100]: loss_d: 1.156, loss_g: 1.110\n",
            "[53/100]: loss_d: 1.179, loss_g: 1.063\n",
            "[54/100]: loss_d: 1.178, loss_g: 1.057\n",
            "[55/100]: loss_d: 1.181, loss_g: 1.066\n",
            "[56/100]: loss_d: 1.177, loss_g: 1.094\n",
            "[57/100]: loss_d: 1.175, loss_g: 1.072\n",
            "[58/100]: loss_d: 1.183, loss_g: 1.041\n",
            "[59/100]: loss_d: 1.197, loss_g: 1.043\n",
            "[60/100]: loss_d: 1.186, loss_g: 1.037\n",
            "[61/100]: loss_d: 1.191, loss_g: 1.046\n",
            "[62/100]: loss_d: 1.197, loss_g: 1.030\n",
            "[63/100]: loss_d: 1.211, loss_g: 0.988\n",
            "[64/100]: loss_d: 1.203, loss_g: 1.048\n",
            "[65/100]: loss_d: 1.201, loss_g: 1.019\n",
            "[66/100]: loss_d: 1.212, loss_g: 1.011\n",
            "[67/100]: loss_d: 1.188, loss_g: 1.039\n",
            "[68/100]: loss_d: 1.208, loss_g: 1.015\n",
            "[69/100]: loss_d: 1.206, loss_g: 1.027\n",
            "[70/100]: loss_d: 1.201, loss_g: 1.019\n",
            "[71/100]: loss_d: 1.204, loss_g: 1.027\n",
            "[72/100]: loss_d: 1.225, loss_g: 0.980\n",
            "[73/100]: loss_d: 1.215, loss_g: 1.015\n",
            "[74/100]: loss_d: 1.218, loss_g: 0.994\n",
            "[75/100]: loss_d: 1.233, loss_g: 0.964\n",
            "[76/100]: loss_d: 1.230, loss_g: 0.971\n",
            "[77/100]: loss_d: 1.228, loss_g: 0.980\n",
            "[78/100]: loss_d: 1.226, loss_g: 0.980\n",
            "[79/100]: loss_d: 1.233, loss_g: 0.962\n",
            "[80/100]: loss_d: 1.228, loss_g: 0.994\n",
            "[81/100]: loss_d: 1.234, loss_g: 0.970\n",
            "[82/100]: loss_d: 1.232, loss_g: 0.968\n",
            "[83/100]: loss_d: 1.238, loss_g: 0.962\n",
            "[84/100]: loss_d: 1.239, loss_g: 0.955\n",
            "[85/100]: loss_d: 1.249, loss_g: 0.942\n",
            "[86/100]: loss_d: 1.235, loss_g: 0.966\n",
            "[87/100]: loss_d: 1.245, loss_g: 0.948\n",
            "[88/100]: loss_d: 1.242, loss_g: 0.945\n",
            "[89/100]: loss_d: 1.254, loss_g: 0.937\n",
            "[90/100]: loss_d: 1.250, loss_g: 0.943\n",
            "[91/100]: loss_d: 1.249, loss_g: 0.939\n",
            "[92/100]: loss_d: 1.256, loss_g: 0.934\n",
            "[93/100]: loss_d: 1.256, loss_g: 0.943\n",
            "[94/100]: loss_d: 1.250, loss_g: 0.935\n",
            "[95/100]: loss_d: 1.263, loss_g: 0.916\n",
            "[96/100]: loss_d: 1.253, loss_g: 0.933\n",
            "[97/100]: loss_d: 1.259, loss_g: 0.926\n",
            "[98/100]: loss_d: 1.267, loss_g: 0.907\n",
            "[99/100]: loss_d: 1.260, loss_g: 0.929\n",
            "[100/100]: loss_d: 1.245, loss_g: 0.940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDqH2utm43U8",
        "outputId": "dec87b16-45c7-4550-b2ed-1ec430fca34e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-05f239421fa4>:8: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  imageio.mimsave(gif_filename, [imageio.imread(f\"{image_folder}/{img}\") for img in images], duration=0.2)\n"
          ]
        }
      ],
      "source": [
        "import imageio\n",
        "import os\n",
        "\n",
        "image_folder = \"./samples\"\n",
        "gif_filename = \"gan_training.gif\"\n",
        "\n",
        "images = sorted([img for img in os.listdir(image_folder) if img.endswith(\".png\")], key=lambda x: int(x[6:-4]))\n",
        "imageio.mimsave(gif_filename, [imageio.imread(f\"{image_folder}/{img}\") for img in images], duration=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def convert_gif_to_mp4(input_gif, output_mp4):\n",
        "    clip = VideoFileClip(input_gif)\n",
        "    clip.write_videofile(output_mp4, codec=\"libx264\", fps=clip.fps)\n",
        "\n",
        "# Example usage\n",
        "convert_gif_to_mp4(\"gan_training.gif\", \"output.mp4\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b8d0-h7CcuD",
        "outputId": "f38f6be9-f668-4cd5-854c-55fec1c6a170"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video output.mp4.\n",
            "Moviepy - Writing video output.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready output.mp4\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}